---
layout: post
title: System.IO.Pipelines, высокоэффективный IO в .NET
category: .net
tags: [.net, development, theory]
---

[blogs.msdn.microsoft.com](https://blogs.msdn.microsoft.com/dotnet/2018/07/09/system-io-pipelines-high-performance-io-in-net/)

[System.IO.Pipelines](https://www.nuget.org/packages/System.IO.Pipelines/) — это новая библиотека, упрощающая организацию кода в .NET. Трудно обеспечить высокую производительность и точность, если приходится иметь дело со сложным кодом. Задача System.IO.Pipelines — упростить код. Подробнее под катом!

Библиотека появилась в результате усилий команды разработчиков .NET Core, которые стремились сделать Kestrel одним из [самых быстрых веб-серверов в отрасли](https://www.techempower.com/benchmarks/#section=data-r16&hw=ph&test=plaintext). Она изначально задумывалась как часть реализации Kestrel, но превратилась в повторно используемый API, доступный в версии 2.1 в качестве BCL API первого класса (System.IO.Pipelines).

# Какие проблемы она решает?

Чтобы правильно анализировать данные из потока или сокета, требуется написать большой объем стандартного кода. При этом существует множество подводных камней, которые усложняют и сам код, и его поддержку.

# Какие сложности возникают сегодня?

Начнем с простой задачи. Нам необходимо написать TCP-сервер, который получает от клиента сообщения с разделителями строк (\n).

# Сервер TCP с NetworkStream

ОТСТУПЛЕНИЕ: как и в любой задаче, требующей высокой производительности, каждый конкретный случай стоит рассматривать исходя из особенностей вашего приложения. Возможно, тратить ресурсы на использование различных подходов, о которых пойдет речь далее, не имеет смысла, если масштаб сетевого приложения не очень велик.
Обычный код .NET перед использованием конвейеров выглядит примерно так:

    // Process a single line from the buffer

см. [sample1.cs](https://gist.github.com/terrajobst/ee86ab15d1d7a1d5869d1c1f2443f3b3#file-sample1-%3Ci%3Ecs) на GitHub
Вероятно, этот код будет работать при локальном тестировании, но он имеет ряд ошибок:

- Возможно, после одного вызова ReadAsync не будет получено целое сообщение (до конца строки).
- Он игнорирует результат работы метода stream.ReadAsync() — количество данных, фактически переданных в буфер.
- Код не обрабатывает прием нескольких строк в одном вызове ReadAsync.

Это наиболее распространенные ошибки чтения потоковых данных. Чтобы их избежать, необходимо внести ряд изменений:

- Нужно буферизовать входящие данные, пока не будет найдена новая строка.
- Необходимо проанализировать все строки, возвращаемые в буфер.

    // EOF// Keep track of the amount of buffered bytes// Look for a EOL in the buffered data// Calculate the length of the line based on the offset// Process the line// Move the bytesConsumed to skip past the line we consumed (including \n)

см. [sample2.cs](https://gist.github.com/terrajobst/8e077db206883ca156dfdb7643969c76#file-%3Ci%3Esample2-cs) на GitHub
Повторюсь: это могло бы сработать при локальном тестировании, но иногда встречаются строки длиной больше 1 Кб (1024 байта). Необходимо увеличить размер входного буфера до тех пор, пока не будет найдена новая строка.
Кроме того, мы собираем буферы в массив при обработке длинных строк. Мы можем улучшить этот процесс с помощью ArrayPool, что позволит избежать повторного распределения буферов во время анализа длинных строк, поступающих от клиента.

    // Calculate the amount of bytes remaining in the buffer// Double the buffer size and copy the previously buffered data into the new buffer// Return the old buffer to the pool// EOF// Keep track of the amount of buffered bytes// Look for a EOL in the buffered data// Calculate the length of the line based on the offset// Process the line// Move the bytesConsumed to skip past the line we consumed (including \n)

см. [sample3.cs](https://gist.github.com/terrajobst/568dad7aa8e831cf4fcb48ca370ca251#file-sample3-cs) на GitHub

Код работает, но теперь изменился размер буфера, в результате появляется множество его копий. Также используется больше памяти, поскольку логика не сокращает буфер после обработки строк. Чтобы этого избежать, можно сохранять список буферов, а не менять каждый раз размер буфера при поступлении строк длиннее 1 Кб.
Кроме того, мы не увеличиваем буфер размером 1 Кб, пока он полностью не опустеет. Это значит, что мы будем передавать в ReadAsync буферы все меньшего размера, в результате возрастет число вызовов операционной системы.
Мы постараемся исключить это и будем выделять новый буфер, как только размер существующего станет меньше 512 байт:

    // Calculate the amount of bytes remaining in the buffer// Allocate a new segment// Keep track of the amount of buffered bytes// Look for a EOL in the list of segments// Process the line// Drop fully consumed segments from the list so we don't look at them again// Return all segments unless this is the current segment// Start from the correct offset// Return the buffer index and the index within that segment where EOL was found

см. [sample4.cs](https://gist.github.com/terrajobst/aed8731297b8e8268ae6a37ebfc33146#file-sample4-cs) на GitHub

В итоге код существенно усложняется. Во время поиска разделителя мы отслеживаем заполненные буферы. Для этого используется List, который отображает буферизованные данные при поиске нового разделителя строк. В результате ProcessLine и IndexOf будут принимать List вместо byte[], offset и count. Логика синтаксического анализа начнет обрабатывать один сегмент буфера или несколько.
И теперь сервер будет обрабатывать частичные сообщения и использовать объединенную память, чтобы уменьшить общее потребление памяти. Однако нужно сделать еще ряд изменений:

1. Из ArrayPoolbyte мы используем только Byte[] — стандартно управляемые массивы. Иными словами, при выполнении функции ReadAsync или WriteAsync срок действия буферов привязывается ко времени осуществления асинхронной операции (чтобы взаимодействовать с собственными API ввода-вывода операционной системы). Поскольку закрепленная память не может перемещаться, это сказывается на производительности сборщика мусора и может вызвать фрагментацию массива. Возможно, реализацию пула придется изменить, в зависимости от того, как долго асинхронные операции будут ожидать исполнения.
2. Пропускную способность можно улучшить, если разорвать связь между логикой чтения и обработки. Мы получаем эффект пакетной обработки, и теперь логика синтаксического анализа сможет считывать большие объемы данных, обрабатывая большие блоки буферов, а не анализируя отдельные строки. В результате код усложняется еще больше:
    - Необходимо создать два цикла, работающих независимо друг от друга. Первый будет считывать данные из сокета, а второй — анализировать буферы.
    - Нужен способ сообщать логике синтаксического анализа, что данные становятся доступны.
    - Также необходимо определить, что произойдет, если цикл будет считывать данные из сокета слишком быстро. Нам нужен способ регулировать цикл считывания, если логика синтаксического анализа не поспевает за ним. Обычно это называют «управлением потоком» или «сопротивлением потоку».
    - Мы должны убедиться, что данные передаются безопасно. Теперь набор буферов используется и циклом считывания, и циклом синтаксического анализа, они работают независимо друг от друга на разных потоках.
    - Логика управления памятью также задействуется двумя разными фрагментами кода: заимствующим данные из буферного пула, который считывает данные из сокета, и возвращающим из буферного пула, который является логикой синтаксического анализа.
    - Нужно быть предельно осторожными с возвратом буферов после исполнения логики синтаксического анализа. Иначе есть вероятность того, что мы вернем буфер, в который все еще ведется запись логики чтения сокета.

Сложность начинает зашкаливать (а это далеко не все случаи!). Для создания высокопроизводительной сети нужно написать очень сложный код.
Цель System.IO.Pipelines — упростить эту процедуру.

### **TCP-сервер и System.IO.Pipelines**

Давайте посмотрим, как работает System.IO.Pipelines:

    // Allocate at least 512 bytes from the PipeWriter// Tell the PipeWriter how much was read from the Socket// Make the data available to the PipeReader// Tell the PipeReader that there's no more data coming// Look for a EOL in the buffer// Process the line// Skip the line + the \n character (basically position)// Tell the PipeReader how much of the buffer we have consumed// Stop reading if there's no more data coming// Mark the PipeReader as complete

см. [sample5.cs](https://gist.github.com/terrajobst/7e04b424ab279e711eece8f6b1c233d8#file-sample5-cs) на GitHub

В конвейерной версии нашего считывателя строк есть два цикла:

- FillPipeAsync считывает из сокета и записывает в PipeWriter.
- ReadPipeAsync считывает из PipeReader и анализирует входящие строки.

В отличие от первых примеров, здесь нет специально назначенных буферов. Это одна из основных функций System.IO.Pipelines. Все задачи по управлению буферами передаются реализациям PipeReader/PipeWriter.
Процедура упрощается: мы используем код только для бизнес-логики вместо того, чтобы реализовывать сложное управление буферами.
В первом цикле сначала вызывается PipeWriter.GetMemory(int), чтобы получить определенный объем памяти от основного записывателя. Затем вызывается PipeWriter.Advance(int), который сообщает PipeWriter, сколько данных фактически записано в буфер. После этого следует вызов PipeWriter.FlushAsync(), чтобы PipeReader получил доступ к данным.
Второй цикл потребляет буферы, которые были записаны PipeWriter, но изначально поступили от сокета. Когда возвращается запрос к PipeReader.ReadAsync(), мы получаем ReadResult, содержащий два важных сообщения: данные, считанные в форме ReadOnlySequence, а также логический тип данных IsCompleted, который сообщает считывателю, закончил ли записыватель работу (EOF). Когда будет найден разделитель конца строки (EOL) и проанализирована строка, мы разделим буфер на части, чтобы пропустить уже обработанный фрагмент. После этого вызывается PipeReader.AdvanceTo, и он сообщает PipeReader, сколько данных было потреблено.
В конце каждого цикла завершается работа и считывателя, и записывателя. В результате основной канал высвобождает всю выделенную память.

# System.IO.Pipelines

### **Частичное чтение**

Кроме управления памятью System.IO.Pipelines выполняет другую важную функцию: просматривает данные в канале, но не потребляет их.
У PipeReader есть два основных API: ReadAsync и AdvanceTo. ReadAsync получает данные из канала, AdvanceTo сообщает PipeReader о том, что эти буферы больше не требуются считывателю, поэтому от них можно избавиться (например, вернуть в основной буферный пул).
Ниже приведен пример анализатора HTTP, который считывает данные из буферов частичных данных канала, пока не получит подходящую начальную строку.

[](https://www.notion.so/16b502f4795641329021a562a0baeeb6#b4fd0d47dd7e45dc945818f17323d164)

# ReadOnlySequenceT

Реализация канала хранит список связанных буферов, передающихся между PipeWriter и PipeReader. PipeReader.ReadAsync раскрывает ReadOnlySequence, являющийся новым типом BCL и состоящий из одного или нескольких сегментов ReadOnlyMemory<Т>. Он похож на Span или Memory, что дает нам возможность взглянуть на массивы и строки.

[](https://www.notion.so/16b502f4795641329021a562a0baeeb6#7fdfe0bfc17746709b46c064e3148265)

Внутри канала есть указатели, которые показывают, где в общем наборе выделенных данных располагаются считыватель и записыватель, а также обновляют их по мере записи и чтения данных. SequencePosition представляет собой единую точку в связанном списке буферов и используется для эффективного разделения ReadOnlySequence<Т>.
Поскольку ReadOnlySequence<Т> поддерживает один сегмент и более, то стандартной операцией высокопроизводительной логики является разделение быстрых и медленных путей исходя из количества сегментов.
В качестве примера приведем функцию, преобразующую ASCII ReadOnlySequence в строку:

    string GetAsciiString(ReadOnlySequence<byte> buffer)
    	{
    	    if (buffer.IsSingleSegment)
    	    {
    	        return Encoding.ASCII.GetString(buffer.First.Span);
    	    }
    	
    
    	    return string.Create((int)buffer.Length, buffer, (span, sequence) =>
    	    {
    	        foreach (var segment in sequence)
    	        {
    	            Encoding.ASCII.GetChars(segment.Span, span);
    	
    
    	            span = span.Slice(segment.Length);
    	        }
    	    });
    	}

см.

[sample6.cs](https://gist.github.com/terrajobst/6e1bea5bec4591edd7c5fe5416ce7f56#file-sample6-cs)

на GitHub

### **Сопротивление потоку и управление потоком**

В идеале чтение и анализ работают совместно: поток чтения потребляет данные из сети и помещает их в буферы, в то время как поток анализа создает подходящие структуры данных. Обычно анализ занимает больше времени, чем простое копирование блоков данных из сети. В результате поток чтения может с легкостью перегрузить поток анализа. Поэтому поток чтения будет вынужден либо замедлить работу, либо потреблять больше памяти, чтобы сохранять данные для потока анализа. Чтобы обеспечить оптимальную производительность, необходим баланс между частотой пауз и выделением большого объема памяти.
Для решения этой проблемы конвейер имеет две функции управления потоком данных: PauseWriterThreshold и ResumeWriterThreshold. PauseWriterThreshold определяет, сколько данных необходимо буферизовать до приостановки PipeWriter.FlushAsync. ResumeWriterThreshold определяет, сколько памяти может потребить считыватель до возобновления работы записывателя.

[](https://www.notion.so/16b502f4795641329021a562a0baeeb6#fb104013aa0148d08c250a97743411ed)

PipeWriter.FlushAsync «блокируется», когда количество данных в конвейерном потоке превысит лимит, установленный в PauseWriterThreshold, и «разблокируется», когда оно станет ниже установленного в ResumeWriterThreshold. Чтобы предотвратить превышение лимита потребления, используются всего два значения.

### **Планирование ввода-вывода**

При использовании async/await последующие операции обычно вызываются либо в потоках пула, либо в текущем SynchronizationContext.
При осуществлении ввода-вывода очень важно тщательно контролировать, где он выполняется, чтобы эффективнее использовать кэш процессора. Это имеет критическое значение для высокопроизводительных приложений, таких как веб-серверы. System.IO.Pipelines использует PipeScheduler, чтобы определить место выполнения асинхронных ответных вызовов. Это позволяет очень точно контролировать, какие потоки использовать для ввода-вывода.
Пример практического применения — транспорт Kestrel Libuv, в котором обратные вызовы ввода-вывода выполняются по выделенным каналам цикла событий.

# Есть и другие преимущества шаблона PipeReader

- Некоторые базовые системы поддерживают «ожидание без буферизации»: буфер не нужно выделять то тех пор, пока в базовой системе не появятся доступные данные. Так, в Linux с epoll можно не предоставлять буфер для считывания до тех пор, пока данные не будут подготовлены. Это позволяет избежать ситуации, когда имеется множество потоков, ожидающих данные, и требуется сразу же резервировать огромный объем памяти.
- Конвейер по умолчанию упрощает запись модульных тестов сетевого кода: логика синтаксического анализа отделена от сетевого кода, и модульные тесты запускают эту логику только в буферах в памяти, а не потребляют ее непосредственно из сети. Он также упрощает тестирование сложных шаблонов с отправкой частичных данных. ASP.NET Core использует его для проверки различных аспектов http-средств синтаксического анализа Kestrel.
- Системы, позволяющие пользовательскому коду задействовать основные буферы ОС (например, зарегистрированные API ввода-вывода Windows), изначально подходят для использования конвейеров, поскольку реализация PipeReader всегда предоставляет буферы.

### **Другие связанные типы**

Мы также добавили в System.IO.Pipelines ряд новых простых типов BCL:

- [MemoryPoolT](https://docs.microsoft.com/en-us/dotnet/api/system.buffers.memorypool-1?view=netcore-2.1), [IMemoryOwnerT](https://docs.microsoft.com/en-us/dotnet/api/system.buffers.imemoryowner-1?view=netcore-2.1), [MemoryManagerT](https://docs.microsoft.com/en-us/dotnet/api/system.buffers.memorymanager-1?view=netcore-2.1). В .NET Core 1.0 был добавлен [ArrayPoolT](https://docs.microsoft.com/en-us/dotnet/api/system.buffers.arraypool-1?view=netcore-2.1), а в .NET Core 2.1 теперь имеется более общее абстрактное представление для пула, который работает с любыми MemoryT. Мы получаем точку расширяемости, позволяющую осуществлять более продвинутые стратегии распределения, а также контролировать управление буферами (например, использовать предустановленные буферы вместо исключительно управляемых массивов).
- [IBufferWriterT](https://docs.microsoft.com/en-us/dotnet/api/system.buffers.ibufferwriter-1?view=netcore-2.1) представляет собой приемник для записи синхронных буферизованных данных (реализуется PipeWriter).
- [IValueTaskSource](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.sources.ivaluetasksource-1?view=netcore-2.1) — [ValueTaskT](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.valuetask-1?view=netcore-2.1) существует со времени выпуска .NET Core 1.1, но в .NET Core 2.1 приобрел чрезвычайно эффективные инструменты, обеспечивающие бесперебойные асинхронные операции без распределения. Дополнительную информацию см. [здесь](https://github.com/dotnet/corefx/issues/27445).

# Как использовать конвейеры?

API находятся в nuget-пакете [System.IO.Pipelines](https://www.nuget.org/packages/System.IO.Pipelines/).
Пример приложения сервера .NET Server 2.1, использующего конвейеры для обработки строчных сообщений (из примера выше) см. [здесь](https://github.com/davidfowl/TcpEcho) . Его можно запустить с помощью dotnet run (или Visual Studio). В примере ожидается передача данных от сокета на порту 8087, затем полученные сообщения записываются на консоль. Для подключения к порту 8087 можно использовать клиент, например netcat или putty. Отправьте строчное сообщение и посмотрите, как это работает.
На данный момент конвейер работает в Kestrel и SignalR, и мы надеемся, что она найдет более широкое применение во множестве сетевых библиотек и компонентов сообщества .NET в будущем.